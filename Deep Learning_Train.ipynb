{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GISTDA Wildfire Machine Learning Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library Packages\n",
    "\n",
    "#### Core Libraries\n",
    "- **numpy**: A powerful library for numerical computing, providing support for arrays, matrices, and a wide range of mathematical operations.\n",
    "- **pandas**: A versatile library for data manipulation and analysis, offering easy-to-use data structures like `DataFrame` for handling tabular data.\n",
    "\n",
    "#### Visualization Libraries\n",
    "- **matplotlib.pyplot**: A plotting library for creating static, animated, and interactive visualizations in Python.\n",
    "- **seaborn**: Built on top of Matplotlib, this library provides a high-level interface for drawing attractive and informative statistical graphics.\n",
    "\n",
    "#### Geospatial Libraries\n",
    "- **rasterio**: A library for reading and writing geospatial raster data, commonly used for remote sensing and GIS applications.\n",
    "  - **rasterio.windows.Window**: A tool to define a specific rectangular region (window) within a raster dataset for operations.\n",
    "\n",
    "#### Logging\n",
    "- **logging**: A built-in Python module to record log messages, useful for debugging and monitoring program execution.\n",
    "\n",
    "#### File Handling\n",
    "- **os**: A module providing tools to interact with the operating system, such as reading/writing files and directory management.\n",
    "- **pickle**: A module for serializing and deserializing Python objects for storage or transmission.\n",
    "\n",
    "#### Data Preprocessing\n",
    "- **sklearn.preprocessing.MinMaxScaler**: A preprocessing tool from scikit-learn that scales and normalizes data within a specified range, often [0, 1].\n",
    "\n",
    "#### Display Utilities\n",
    "- **IPython.display.display**: A utility to control the display of outputs in Jupyter notebooks.\n",
    "- **IPython.display.Markdown**: Enables the rendering of Markdown text in a Jupyter notebook.\n",
    "\n",
    "#### Deep Learning Libraries\n",
    "- **tensorflow**: A popular open-source framework for machine learning and deep learning. It supports building and training neural networks efficiently.\n",
    "  - **tensorflow.keras.models.Sequential**: A simple model-building API for stacking layers sequentially.\n",
    "  - **tensorflow.keras.layers.Dense**: A fully connected neural network layer.\n",
    "  - **tensorflow.keras.layers.Dropout**: A regularization technique to prevent overfitting by randomly dropping neurons during training.\n",
    "  - **tensorflow.keras.callbacks.EarlyStopping**: Stops training when a monitored metric stops improving.\n",
    "  - **tensorflow.keras.callbacks.ReduceLROnPlateau**: Adjusts the learning rate when a metric stops improving.\n",
    "\n",
    "#### Evaluation Metrics\n",
    "- **sklearn.metrics.classification_report**: Generates a detailed report of classification metrics, including precision, recall, and F1 score.\n",
    "- **sklearn.metrics.confusion_matrix**: Computes a confusion matrix to evaluate classification accuracy.\n",
    "- **sklearn.metrics.roc_curve**: Computes Receiver Operating Characteristic (ROC) curve metrics.\n",
    "- **sklearn.metrics.auc**: Computes the Area Under the Curve (AUC) for a ROC curve.\n",
    "\n",
    "#### Typing\n",
    "- **typing**: Provides tools for type annotations to improve code clarity and static analysis.\n",
    "  - **Tuple, Dict, Any, List**: Common data types used in type hinting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rasterio\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import display, Markdown\n",
    "from rasterio.windows import Window\n",
    "from typing import Tuple, Dict, Any, List\n",
    "from dask import delayed, compute\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Raster GeoTIFF files\n",
    "\n",
    "This code reads large raster files in manageable chunks, processes each chunk, and stores the data in a consolidated DataFrame.\n",
    "\n",
    "1. **Folder Path and Chunk Size**: Sets the path to the folder containing raster files (`raster_train_file_path`) and defines the chunk size (`CHUNK_SIZE`).\n",
    "\n",
    "2. **`read_raster_in_chunks` Function**:\n",
    "   - Reads a raster file chunk-by-chunk.\n",
    "   - For each chunk, it extracts data from all bands, along with the pixel coordinates.\n",
    "   - Stores each chunk's data in a temporary DataFrame, which is added to a list.\n",
    "\n",
    "3. **Task Creation**:\n",
    "   - Creates a list of tasks using Dask's `@delayed` to process each raster file in parallel.\n",
    "\n",
    "4. **Compute and Combine**:\n",
    "   - Computes each task to get individual DataFrames for each file, then combines them into a final DataFrame (`final_df`).\n",
    "\n",
    "5. **Debug Outputs**:\n",
    "   - Prints the shape, columns, and a sample of the final DataFrame for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (48168960, 20)\n",
      "\n",
      "DataFrame columns: ['raster_file', 'subfolder', 'x', 'y', 'B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B09', 'B10', 'B11', 'B12', 'B13', 'B14', 'B15', 'B16']\n",
      "\n",
      "Sample of data:\n",
      "                            raster_file     subfolder  x  y    B01     B02  \\\n",
      "0  T46QGF_20230316T040541_chunk_0_0.tif  Raster_Train  0  0    1.0  1554.0   \n",
      "1  T46QGF_20230316T040541_chunk_0_0.tif  Raster_Train  0  1    1.0  1600.0   \n",
      "2  T46QGF_20230316T040541_chunk_0_0.tif  Raster_Train  0  2  603.0  1592.0   \n",
      "3  T46QGF_20230316T040541_chunk_0_0.tif  Raster_Train  0  3  603.0  1678.0   \n",
      "4  T46QGF_20230316T040541_chunk_0_0.tif  Raster_Train  0  4  858.0  1698.0   \n",
      "\n",
      "      B03     B04     B05     B06     B07     B08     B09     B10     B11  \\\n",
      "0  1752.0  1930.0  2277.0  2576.0  2712.0  2812.0  2959.0  3042.0  3627.0   \n",
      "1  1788.0  1912.0  2277.0  2576.0  2712.0  2850.0  2959.0  3042.0  3627.0   \n",
      "2  1790.0  2002.0  2413.0  2643.0  2836.0  2782.0  3120.0  3042.0  3786.0   \n",
      "3  1863.0  2142.0  2413.0  2643.0  2836.0  2974.0  3120.0  3042.0  3786.0   \n",
      "4  1932.0  2224.0  2504.0  2747.0  2843.0  3004.0  3109.0  3042.0  3696.0   \n",
      "\n",
      "      B12       B13       B14       B15  B16  \n",
      "0  2993.0  0.435584  0.185997 -0.232252  0.0  \n",
      "1  2993.0  0.435584  0.196976 -0.228978  0.0  \n",
      "2  3110.0  0.440843  0.163043 -0.216973  0.0  \n",
      "3  3110.0  0.440843  0.162627 -0.229688  0.0  \n",
      "4  3002.0  0.429292  0.149197 -0.217180  0.0  \n"
     ]
    }
   ],
   "source": [
    "# Define the folder containing the raster files\n",
    "raster_train_file_path = r'Raster_Train'\n",
    "\n",
    "# Parameters for chunk size\n",
    "CHUNK_SIZE = 1024\n",
    "\n",
    "@delayed\n",
    "def read_raster_in_chunks(raster_path, file, root):\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        height, width = src.height, src.width\n",
    "        num_bands = src.count\n",
    "        band_names = [f'B{str(i).zfill(2)}' for i in range(1, num_bands + 1)]\n",
    "        chunk_dfs = []\n",
    "        \n",
    "        # Loop over the raster in chunks\n",
    "        for row in range(0, height, CHUNK_SIZE):\n",
    "            for col in range(0, width, CHUNK_SIZE):\n",
    "                window = Window(col_off=col, row_off=row, \n",
    "                              width=min(CHUNK_SIZE, width - col),\n",
    "                              height=min(CHUNK_SIZE, height - row))\n",
    "                \n",
    "                # Read all bands at once\n",
    "                data = src.read(window=window)\n",
    "                \n",
    "                # Check if chunk contains any data\n",
    "                if np.any(data):\n",
    "                    rows, cols = data[0].shape\n",
    "                    \n",
    "                    # Create base DataFrame with coordinates\n",
    "                    row_coords, col_coords = np.meshgrid(\n",
    "                        np.arange(row, row + rows),\n",
    "                        np.arange(col, col + cols),\n",
    "                        indexing=\"ij\"\n",
    "                    )\n",
    "                    \n",
    "                    chunk_df = pd.DataFrame({\n",
    "                        'raster_file': file,\n",
    "                        'subfolder': os.path.basename(root),\n",
    "                        'x': row_coords.flatten(),\n",
    "                        'y': col_coords.flatten()\n",
    "                    })\n",
    "                    \n",
    "                    # Add each band's data\n",
    "                    for band_idx, band_name in enumerate(band_names, 1):\n",
    "                        chunk_df[band_name] = data[band_idx-1].flatten()\n",
    "                    \n",
    "                    chunk_dfs.append(chunk_df)\n",
    "        \n",
    "        return pd.concat(chunk_dfs, ignore_index=True) if chunk_dfs else pd.DataFrame()\n",
    "\n",
    "# Create list of tasks\n",
    "dask_dfs = [\n",
    "    read_raster_in_chunks(os.path.join(root, file), file, root)\n",
    "    for root, dirs, files in os.walk(raster_train_file_path)\n",
    "    for file in files if file.endswith('.tif')\n",
    "]\n",
    "\n",
    "# Compute all tasks\n",
    "dataframes = compute(*dask_dfs)\n",
    "\n",
    "# Combine all DataFrames\n",
    "final_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Debug prints\n",
    "print(\"DataFrame shape:\", final_df.shape)\n",
    "print(\"\\nDataFrame columns:\", final_df.columns.tolist())\n",
    "print(\"\\nSample of data:\")\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA) & Feature Engineering\n",
    "\n",
    "This code performs several operations on a DataFrame (`final_df`), converting it to a Dask DataFrame for distributed processing, renaming columns, and dropping unnecessary columns:\n",
    "\n",
    "1. **Convert to Dask DataFrame**:\n",
    "   - Converts the existing Pandas DataFrame (`final_df`) into a Dask DataFrame (`ddf`) to enable parallel, distributed processing.\n",
    "\n",
    "2. **Rename Columns**:\n",
    "   - Defines a list of new column names for Sentinel-2 bands and other data (`new_col_names`).\n",
    "   - Renames `ddf` columns using this list to make them more descriptive.\n",
    "\n",
    "3. **Drop Unneeded Columns**:\n",
    "   - Drops columns such as `raster_file`, `subfolder`, `x`, `y`, and `dNBR`, keeping only essential information in the DataFrame (`df`).\n",
    "\n",
    "4. **Display DataFrame**:\n",
    "   - Uses `display()` to view the DataFrame when needed, triggering Dask's computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Band_1</th>\n",
       "      <th>Band_2</th>\n",
       "      <th>Band_3</th>\n",
       "      <th>Band_4</th>\n",
       "      <th>Band_5</th>\n",
       "      <th>Band_6</th>\n",
       "      <th>Band_7</th>\n",
       "      <th>Band_8</th>\n",
       "      <th>Band_8A</th>\n",
       "      <th>Band_9</th>\n",
       "      <th>Band_11</th>\n",
       "      <th>Band_12</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>NDWI</th>\n",
       "      <th>Burn_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1554.0</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>2277.0</td>\n",
       "      <td>2576.0</td>\n",
       "      <td>2712.0</td>\n",
       "      <td>2812.0</td>\n",
       "      <td>2959.0</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>3627.0</td>\n",
       "      <td>2993.0</td>\n",
       "      <td>0.185997</td>\n",
       "      <td>-0.232252</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1788.0</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>2277.0</td>\n",
       "      <td>2576.0</td>\n",
       "      <td>2712.0</td>\n",
       "      <td>2850.0</td>\n",
       "      <td>2959.0</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>3627.0</td>\n",
       "      <td>2993.0</td>\n",
       "      <td>0.196976</td>\n",
       "      <td>-0.228978</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>603.0</td>\n",
       "      <td>1592.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>2643.0</td>\n",
       "      <td>2836.0</td>\n",
       "      <td>2782.0</td>\n",
       "      <td>3120.0</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>3786.0</td>\n",
       "      <td>3110.0</td>\n",
       "      <td>0.163043</td>\n",
       "      <td>-0.216973</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>603.0</td>\n",
       "      <td>1678.0</td>\n",
       "      <td>1863.0</td>\n",
       "      <td>2142.0</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>2643.0</td>\n",
       "      <td>2836.0</td>\n",
       "      <td>2974.0</td>\n",
       "      <td>3120.0</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>3786.0</td>\n",
       "      <td>3110.0</td>\n",
       "      <td>0.162627</td>\n",
       "      <td>-0.229688</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858.0</td>\n",
       "      <td>1698.0</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>2224.0</td>\n",
       "      <td>2504.0</td>\n",
       "      <td>2747.0</td>\n",
       "      <td>2843.0</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>3109.0</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>3696.0</td>\n",
       "      <td>3002.0</td>\n",
       "      <td>0.149197</td>\n",
       "      <td>-0.217180</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48168955</th>\n",
       "      <td>1319.0</td>\n",
       "      <td>1414.0</td>\n",
       "      <td>1513.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>1737.0</td>\n",
       "      <td>2038.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>2604.0</td>\n",
       "      <td>2544.0</td>\n",
       "      <td>2814.0</td>\n",
       "      <td>2814.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>0.236761</td>\n",
       "      <td>-0.264999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48168956</th>\n",
       "      <td>1316.0</td>\n",
       "      <td>1412.0</td>\n",
       "      <td>1553.0</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2269.0</td>\n",
       "      <td>2510.0</td>\n",
       "      <td>2838.0</td>\n",
       "      <td>2772.0</td>\n",
       "      <td>3203.0</td>\n",
       "      <td>3053.0</td>\n",
       "      <td>2263.0</td>\n",
       "      <td>0.274933</td>\n",
       "      <td>-0.292644</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48168957</th>\n",
       "      <td>1316.0</td>\n",
       "      <td>1414.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>2269.0</td>\n",
       "      <td>2510.0</td>\n",
       "      <td>2721.0</td>\n",
       "      <td>2772.0</td>\n",
       "      <td>3203.0</td>\n",
       "      <td>3053.0</td>\n",
       "      <td>2263.0</td>\n",
       "      <td>0.246450</td>\n",
       "      <td>-0.272387</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48168958</th>\n",
       "      <td>1319.0</td>\n",
       "      <td>1412.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>1694.0</td>\n",
       "      <td>2064.0</td>\n",
       "      <td>2489.0</td>\n",
       "      <td>2743.0</td>\n",
       "      <td>2819.0</td>\n",
       "      <td>3086.0</td>\n",
       "      <td>3203.0</td>\n",
       "      <td>3337.0</td>\n",
       "      <td>2494.0</td>\n",
       "      <td>0.249280</td>\n",
       "      <td>-0.288980</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48168959</th>\n",
       "      <td>1319.0</td>\n",
       "      <td>1419.0</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>1678.0</td>\n",
       "      <td>2064.0</td>\n",
       "      <td>2489.0</td>\n",
       "      <td>2743.0</td>\n",
       "      <td>3035.0</td>\n",
       "      <td>3086.0</td>\n",
       "      <td>3203.0</td>\n",
       "      <td>3337.0</td>\n",
       "      <td>2494.0</td>\n",
       "      <td>0.287927</td>\n",
       "      <td>-0.316703</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48168960 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Band_1  Band_2  Band_3  Band_4  Band_5  Band_6  Band_7  Band_8  \\\n",
       "0            1.0  1554.0  1752.0  1930.0  2277.0  2576.0  2712.0  2812.0   \n",
       "1            1.0  1600.0  1788.0  1912.0  2277.0  2576.0  2712.0  2850.0   \n",
       "2          603.0  1592.0  1790.0  2002.0  2413.0  2643.0  2836.0  2782.0   \n",
       "3          603.0  1678.0  1863.0  2142.0  2413.0  2643.0  2836.0  2974.0   \n",
       "4          858.0  1698.0  1932.0  2224.0  2504.0  2747.0  2843.0  3004.0   \n",
       "...          ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "48168955  1319.0  1414.0  1513.0  1607.0  1737.0  2038.0  2220.0  2604.0   \n",
       "48168956  1316.0  1412.0  1553.0  1614.0  1949.0  2269.0  2510.0  2838.0   \n",
       "48168957  1316.0  1414.0  1556.0  1645.0  1949.0  2269.0  2510.0  2721.0   \n",
       "48168958  1319.0  1412.0  1555.0  1694.0  2064.0  2489.0  2743.0  2819.0   \n",
       "48168959  1319.0  1419.0  1575.0  1678.0  2064.0  2489.0  2743.0  3035.0   \n",
       "\n",
       "          Band_8A  Band_9  Band_11  Band_12      NDVI      NDWI  Burn_Label  \n",
       "0          2959.0  3042.0   3627.0   2993.0  0.185997 -0.232252         0.0  \n",
       "1          2959.0  3042.0   3627.0   2993.0  0.196976 -0.228978         0.0  \n",
       "2          3120.0  3042.0   3786.0   3110.0  0.163043 -0.216973         0.0  \n",
       "3          3120.0  3042.0   3786.0   3110.0  0.162627 -0.229688         0.0  \n",
       "4          3109.0  3042.0   3696.0   3002.0  0.149197 -0.217180         0.0  \n",
       "...           ...     ...      ...      ...       ...       ...         ...  \n",
       "48168955   2544.0  2814.0   2814.0   2122.0  0.236761 -0.264999         0.0  \n",
       "48168956   2772.0  3203.0   3053.0   2263.0  0.274933 -0.292644         0.0  \n",
       "48168957   2772.0  3203.0   3053.0   2263.0  0.246450 -0.272387         0.0  \n",
       "48168958   3086.0  3203.0   3337.0   2494.0  0.249280 -0.288980         0.0  \n",
       "48168959   3086.0  3203.0   3337.0   2494.0  0.287927 -0.316703         0.0  \n",
       "\n",
       "[48168960 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert to Dask DataFrame\n",
    "ddf = pd.DataFrame(final_df)  # Adjust npartitions as needed\n",
    "\n",
    "# Rename Sentinel-2 Bands columns\n",
    "new_col_names = ['raster_file', 'subfolder', 'x', 'y', 'Band_1', 'Band_2', 'Band_3', 'Band_4', 'Band_5', \n",
    "                 'Band_6', 'Band_7', 'Band_8', 'Band_8A', 'Band_9', 'Band_11', 'Band_12', 'dNBR',\n",
    "                 'NDVI', 'NDWI', 'Burn_Label']\n",
    "\n",
    "# Rename columns\n",
    "final_df.columns = new_col_names\n",
    "\n",
    "# Drop columns using Dask method\n",
    "df = final_df.drop(columns=['raster_file', 'subfolder', 'x', 'y', 'dNBR'])\n",
    "display(df)  # Compute only when you need to display or save results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Burn Class\n",
    "\n",
    "This code checks and displays the counts of burn records in the DataFrame:\n",
    "\n",
    "1. **Count Burn Labels**:\n",
    "   - Counts occurrences in the `Burn_Label` column to determine the number of \"Burn\" and \"Unburn\" records.\n",
    "   - Renames the labels: `1` to \"Burn\" and `0` to \"Unburn\" for readability.\n",
    "\n",
    "2. **Display Counts**:\n",
    "   - Prints the resulting counts to show the distribution of burn and unburned areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burn_Label\n",
      "Unburn    40165739\n",
      "Burn       8003221\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check Burn Records\n",
    "burn_counts = df['Burn_Label'].value_counts().rename(index={1: 'Burn', 0: 'Unburn'})\n",
    "\n",
    "# Display the counts with labels\n",
    "print(burn_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling\n",
    "\n",
    "This code performs downsampling to balance the dataset by reducing the number of \"Unburn\" records to match the count of \"Burn\" records:\n",
    "\n",
    "1. **Get Burn Count**:\n",
    "   - Retrieves the count of \"Burn\" records from `burn_counts`.\n",
    "\n",
    "2. **Sample Unburned Records**:\n",
    "   - Selects a random sample of \"Unburn\" records, equal in size to the number of \"Burn\" records, using a fixed `random_state` for reproducibility.\n",
    "\n",
    "3. **Combine Burn and Downsampled Unburn Records**:\n",
    "   - Combines all \"Burn\" records with the downsampled \"Unburn\" sample into a new DataFrame (`downsampled_df`).\n",
    "\n",
    "4. **Check New Burn Record Counts**:\n",
    "   - Counts and displays the \"Burn\" and \"Unburn\" records in `downsampled_df` to verify balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burn_Label\n",
      "Burn      8003221\n",
      "Unburn    8003221\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "burn_count = burn_counts['Burn']\n",
    "unburn_sample = df[df['Burn_Label'] == 0].sample(n=burn_count, random_state=42)\n",
    "\n",
    "downsampled_df = pd.concat([df[df['Burn_Label'] == 1], unburn_sample])\n",
    "\n",
    "# Check Burn Records\n",
    "burn_counts = downsampled_df['Burn_Label'].value_counts().rename(index={1: 'Burn', 0: 'Unburn'})\n",
    "\n",
    "# Display the counts with labels\n",
    "print(burn_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove infinite values\n",
    "\n",
    "This code handles the presence of infinite values and missing data in the `downsampled_df` DataFrame:\n",
    "\n",
    "1. **Replace Infinite Values**:\n",
    "   - Replaces both positive and negative infinite values (`np.inf` and `-np.inf`) with `NaN` using `replace()`. This ensures that infinite values do not interfere with further processing.\n",
    "\n",
    "2. **Drop Rows with Missing Values**:\n",
    "   - Removes any rows containing `NaN` values using `dropna()`, ensuring the DataFrame only contains valid data.\n",
    "\n",
    "3. **Display the DataFrame**:\n",
    "   - Displays the cleaned DataFrame (`downsampled_df`) for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Band_1</th>\n",
       "      <th>Band_2</th>\n",
       "      <th>Band_3</th>\n",
       "      <th>Band_4</th>\n",
       "      <th>Band_5</th>\n",
       "      <th>Band_6</th>\n",
       "      <th>Band_7</th>\n",
       "      <th>Band_8</th>\n",
       "      <th>Band_8A</th>\n",
       "      <th>Band_9</th>\n",
       "      <th>Band_11</th>\n",
       "      <th>Band_12</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>NDWI</th>\n",
       "      <th>Burn_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>703.0</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>1767.0</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>2193.0</td>\n",
       "      <td>2333.0</td>\n",
       "      <td>2382.0</td>\n",
       "      <td>2498.0</td>\n",
       "      <td>2556.0</td>\n",
       "      <td>2473.0</td>\n",
       "      <td>3356.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>0.121688</td>\n",
       "      <td>-0.171395</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>703.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>2193.0</td>\n",
       "      <td>2333.0</td>\n",
       "      <td>2382.0</td>\n",
       "      <td>2410.0</td>\n",
       "      <td>2556.0</td>\n",
       "      <td>2473.0</td>\n",
       "      <td>3356.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>0.098701</td>\n",
       "      <td>-0.144893</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>729.0</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>1796.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>2155.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>2286.0</td>\n",
       "      <td>2272.0</td>\n",
       "      <td>2405.0</td>\n",
       "      <td>2473.0</td>\n",
       "      <td>3118.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>0.066166</td>\n",
       "      <td>-0.117011</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>729.0</td>\n",
       "      <td>1672.0</td>\n",
       "      <td>1846.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>2155.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>2286.0</td>\n",
       "      <td>2266.0</td>\n",
       "      <td>2405.0</td>\n",
       "      <td>2473.0</td>\n",
       "      <td>3118.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>0.064850</td>\n",
       "      <td>-0.102140</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>740.0</td>\n",
       "      <td>1706.0</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>2159.0</td>\n",
       "      <td>2214.0</td>\n",
       "      <td>2234.0</td>\n",
       "      <td>2317.0</td>\n",
       "      <td>2473.0</td>\n",
       "      <td>3010.0</td>\n",
       "      <td>3035.0</td>\n",
       "      <td>0.056265</td>\n",
       "      <td>-0.101578</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41563308</th>\n",
       "      <td>1322.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>1654.0</td>\n",
       "      <td>1686.0</td>\n",
       "      <td>2144.0</td>\n",
       "      <td>2883.0</td>\n",
       "      <td>3140.0</td>\n",
       "      <td>3526.0</td>\n",
       "      <td>3631.0</td>\n",
       "      <td>3584.0</td>\n",
       "      <td>3314.0</td>\n",
       "      <td>2338.0</td>\n",
       "      <td>0.353031</td>\n",
       "      <td>-0.361390</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16455620</th>\n",
       "      <td>1543.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>2164.0</td>\n",
       "      <td>2998.0</td>\n",
       "      <td>3291.0</td>\n",
       "      <td>3924.0</td>\n",
       "      <td>3539.0</td>\n",
       "      <td>3222.0</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>0.388044</td>\n",
       "      <td>-0.379262</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25256050</th>\n",
       "      <td>1411.0</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>1723.0</td>\n",
       "      <td>1762.0</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>2805.0</td>\n",
       "      <td>3027.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>3325.0</td>\n",
       "      <td>3209.0</td>\n",
       "      <td>2277.0</td>\n",
       "      <td>0.275195</td>\n",
       "      <td>-0.285507</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6093295</th>\n",
       "      <td>1515.0</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>2156.0</td>\n",
       "      <td>2470.0</td>\n",
       "      <td>2602.0</td>\n",
       "      <td>2855.0</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>3193.0</td>\n",
       "      <td>3030.0</td>\n",
       "      <td>4361.0</td>\n",
       "      <td>3467.0</td>\n",
       "      <td>0.164341</td>\n",
       "      <td>-0.229133</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32999199</th>\n",
       "      <td>1658.0</td>\n",
       "      <td>1733.0</td>\n",
       "      <td>1828.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2232.0</td>\n",
       "      <td>2399.0</td>\n",
       "      <td>2562.0</td>\n",
       "      <td>2766.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>3054.0</td>\n",
       "      <td>3730.0</td>\n",
       "      <td>3228.0</td>\n",
       "      <td>0.156113</td>\n",
       "      <td>-0.204179</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16006442 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Band_1  Band_2  Band_3  Band_4  Band_5  Band_6  Band_7  Band_8  \\\n",
       "18         703.0  1614.0  1767.0  1956.0  2193.0  2333.0  2382.0  2498.0   \n",
       "19         703.0  1650.0  1800.0  1977.0  2193.0  2333.0  2382.0  2410.0   \n",
       "20         729.0  1689.0  1796.0  1990.0  2155.0  2194.0  2286.0  2272.0   \n",
       "21         729.0  1672.0  1846.0  1990.0  2155.0  2194.0  2286.0  2266.0   \n",
       "22         740.0  1706.0  1822.0  1996.0  2122.0  2159.0  2214.0  2234.0   \n",
       "...          ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41563308  1322.0  1467.0  1654.0  1686.0  2144.0  2883.0  3140.0  3526.0   \n",
       "16455620  1543.0  1550.0  1766.0  1730.0  2164.0  2998.0  3291.0  3924.0   \n",
       "25256050  1411.0  1480.0  1723.0  1762.0  2199.0  2805.0  3027.0  3100.0   \n",
       "6093295   1515.0  1624.0  1884.0  2156.0  2470.0  2602.0  2855.0  3004.0   \n",
       "32999199  1658.0  1733.0  1828.0  2019.0  2232.0  2399.0  2562.0  2766.0   \n",
       "\n",
       "          Band_8A  Band_9  Band_11  Band_12      NDVI      NDWI  Burn_Label  \n",
       "18         2556.0  2473.0   3356.0   3200.0  0.121688 -0.171395         1.0  \n",
       "19         2556.0  2473.0   3356.0   3200.0  0.098701 -0.144893         1.0  \n",
       "20         2405.0  2473.0   3118.0   3100.0  0.066166 -0.117011         1.0  \n",
       "21         2405.0  2473.0   3118.0   3100.0  0.064850 -0.102140         1.0  \n",
       "22         2317.0  2473.0   3010.0   3035.0  0.056265 -0.101578         1.0  \n",
       "...           ...     ...      ...      ...       ...       ...         ...  \n",
       "41563308   3631.0  3584.0   3314.0   2338.0  0.353031 -0.361390         0.0  \n",
       "16455620   3539.0  3222.0   3090.0   2199.0  0.388044 -0.379262         0.0  \n",
       "25256050   3400.0  3325.0   3209.0   2277.0  0.275195 -0.285507         0.0  \n",
       "6093295    3193.0  3030.0   4361.0   3467.0  0.164341 -0.229133         0.0  \n",
       "32999199   2800.0  3054.0   3730.0   3228.0  0.156113 -0.204179         0.0  \n",
       "\n",
       "[16006442 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Replacing infinite with nan \n",
    "downsampled_df.replace([np.inf, -np.inf], np.nan, inplace=True) \n",
    "  \n",
    "# Dropping all the rows with nan values \n",
    "downsampled_df.dropna(inplace=True)\n",
    "\n",
    "# Printing df \n",
    "display(downsampled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate Burn_Label from DataFrame\n",
    "\n",
    "This code separates the `Burn_Label` from the main DataFrame and ensures the label is in the correct format:\n",
    "\n",
    "1. **Separate Burn Label**:\n",
    "   - Extracts the `Burn_Label` column from `downsampled_df` into a new DataFrame (`burn_label`).\n",
    "\n",
    "2. **Remove Burn Label from Main DataFrame**:\n",
    "   - Drops the `Burn_Label` column from `downsampled_df` to ensure only the feature data remains.\n",
    "\n",
    "3. **Convert Burn Label to Integer**:\n",
    "   - Changes the data type of the `burn_label` DataFrame to `int32` to ensure consistent and efficient processing.\n",
    "\n",
    "4. **Display Burn Label**:\n",
    "   - Displays the modified `burn_label` DataFrame to verify the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Burn_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41563308</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16455620</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25256050</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6093295</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32999199</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16006442 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Burn_Label\n",
       "18                 1\n",
       "19                 1\n",
       "20                 1\n",
       "21                 1\n",
       "22                 1\n",
       "...              ...\n",
       "41563308           0\n",
       "16455620           0\n",
       "25256050           0\n",
       "6093295            0\n",
       "32999199           0\n",
       "\n",
       "[16006442 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Seperate Burn_Label from DataFrame\n",
    "burn_label = downsampled_df[['Burn_Label']]\n",
    "\n",
    "# Drop Label from DataFrame\n",
    "downsampled_df = downsampled_df.drop(columns=['Burn_Label'])\n",
    "\n",
    "# Change type of Label to Integer Format\n",
    "burn_label = burn_label.astype('int32')\n",
    "display(burn_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization Data with MinMax Scaler\n",
    "\n",
    "This code normalizes the feature data and saves the normalization model, while also combining it with the `Burn_Label`:\n",
    "\n",
    "1. **List Columns**:\n",
    "   - Creates a list of column names from `downsampled_df` to keep track of the column order after normalization (`cols_norm`).\n",
    "\n",
    "2. **Normalize the Data**:\n",
    "   - Imports `MinMaxScaler` from `sklearn` and fits it to the data in `downsampled_df`, which scales the values between 0 and 1.\n",
    "\n",
    "3. **Save the Scaler**:\n",
    "   - Saves the fitted `MinMaxScaler` model to a specified path (`MinMax_Scaler.pkl`) for later use.\n",
    "\n",
    "4. **Apply Normalization**:\n",
    "   - Normalizes the data by applying the `scaler` to `downsampled_df`, then converts the result back into a DataFrame (`df_norm`) with the original column names.\n",
    "\n",
    "5. **Check Shape**:\n",
    "   - Prints the shape of `df_norm` to confirm the normalization was applied correctly.\n",
    "\n",
    "6. **Concatenate with Burn Label**:\n",
    "   - Combines the normalized feature data (`df_norm`) with the `burn_label` DataFrame, aligning them by their indices and ensuring the result is a complete dataset.\n",
    "\n",
    "7. **Display the DataFrame**:\n",
    "   - Displays the final DataFrame (`df_norm`), which now includes both the normalized features and the `Burn_Label`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df_norm after normalization: (16006442, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Band_1</th>\n",
       "      <th>Band_2</th>\n",
       "      <th>Band_3</th>\n",
       "      <th>Band_4</th>\n",
       "      <th>Band_5</th>\n",
       "      <th>Band_6</th>\n",
       "      <th>Band_7</th>\n",
       "      <th>Band_8</th>\n",
       "      <th>Band_8A</th>\n",
       "      <th>Band_9</th>\n",
       "      <th>Band_11</th>\n",
       "      <th>Band_12</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>NDWI</th>\n",
       "      <th>Burn_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125326</td>\n",
       "      <td>0.129146</td>\n",
       "      <td>0.142650</td>\n",
       "      <td>0.108948</td>\n",
       "      <td>0.215784</td>\n",
       "      <td>0.229196</td>\n",
       "      <td>0.186645</td>\n",
       "      <td>0.107862</td>\n",
       "      <td>0.222532</td>\n",
       "      <td>0.300147</td>\n",
       "      <td>0.155787</td>\n",
       "      <td>0.139978</td>\n",
       "      <td>0.351473</td>\n",
       "      <td>0.544140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125326</td>\n",
       "      <td>0.137107</td>\n",
       "      <td>0.149482</td>\n",
       "      <td>0.111441</td>\n",
       "      <td>0.215784</td>\n",
       "      <td>0.229196</td>\n",
       "      <td>0.186645</td>\n",
       "      <td>0.100358</td>\n",
       "      <td>0.222532</td>\n",
       "      <td>0.300147</td>\n",
       "      <td>0.155787</td>\n",
       "      <td>0.139978</td>\n",
       "      <td>0.324234</td>\n",
       "      <td>0.577361</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.130973</td>\n",
       "      <td>0.145732</td>\n",
       "      <td>0.148654</td>\n",
       "      <td>0.112984</td>\n",
       "      <td>0.206724</td>\n",
       "      <td>0.204690</td>\n",
       "      <td>0.171383</td>\n",
       "      <td>0.088591</td>\n",
       "      <td>0.201452</td>\n",
       "      <td>0.300147</td>\n",
       "      <td>0.139554</td>\n",
       "      <td>0.133560</td>\n",
       "      <td>0.285683</td>\n",
       "      <td>0.612311</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.130973</td>\n",
       "      <td>0.141973</td>\n",
       "      <td>0.159006</td>\n",
       "      <td>0.112984</td>\n",
       "      <td>0.206724</td>\n",
       "      <td>0.204690</td>\n",
       "      <td>0.171383</td>\n",
       "      <td>0.088080</td>\n",
       "      <td>0.201452</td>\n",
       "      <td>0.300147</td>\n",
       "      <td>0.139554</td>\n",
       "      <td>0.133560</td>\n",
       "      <td>0.284123</td>\n",
       "      <td>0.630952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.133362</td>\n",
       "      <td>0.149491</td>\n",
       "      <td>0.154037</td>\n",
       "      <td>0.113696</td>\n",
       "      <td>0.198855</td>\n",
       "      <td>0.198519</td>\n",
       "      <td>0.159936</td>\n",
       "      <td>0.085351</td>\n",
       "      <td>0.189167</td>\n",
       "      <td>0.300147</td>\n",
       "      <td>0.132187</td>\n",
       "      <td>0.129388</td>\n",
       "      <td>0.273951</td>\n",
       "      <td>0.631657</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16006437</th>\n",
       "      <td>0.259774</td>\n",
       "      <td>0.096639</td>\n",
       "      <td>0.119255</td>\n",
       "      <td>0.076905</td>\n",
       "      <td>0.204101</td>\n",
       "      <td>0.326164</td>\n",
       "      <td>0.307154</td>\n",
       "      <td>0.195515</td>\n",
       "      <td>0.372609</td>\n",
       "      <td>0.533993</td>\n",
       "      <td>0.152923</td>\n",
       "      <td>0.084654</td>\n",
       "      <td>0.625597</td>\n",
       "      <td>0.305978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16006438</th>\n",
       "      <td>0.307776</td>\n",
       "      <td>0.114993</td>\n",
       "      <td>0.142443</td>\n",
       "      <td>0.082127</td>\n",
       "      <td>0.208870</td>\n",
       "      <td>0.346439</td>\n",
       "      <td>0.331161</td>\n",
       "      <td>0.229451</td>\n",
       "      <td>0.359765</td>\n",
       "      <td>0.457798</td>\n",
       "      <td>0.137644</td>\n",
       "      <td>0.075733</td>\n",
       "      <td>0.667084</td>\n",
       "      <td>0.283575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16006439</th>\n",
       "      <td>0.279105</td>\n",
       "      <td>0.099513</td>\n",
       "      <td>0.133540</td>\n",
       "      <td>0.085925</td>\n",
       "      <td>0.217215</td>\n",
       "      <td>0.312412</td>\n",
       "      <td>0.289189</td>\n",
       "      <td>0.159192</td>\n",
       "      <td>0.340360</td>\n",
       "      <td>0.479478</td>\n",
       "      <td>0.145761</td>\n",
       "      <td>0.080739</td>\n",
       "      <td>0.533367</td>\n",
       "      <td>0.401099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16006440</th>\n",
       "      <td>0.301694</td>\n",
       "      <td>0.131358</td>\n",
       "      <td>0.166874</td>\n",
       "      <td>0.132685</td>\n",
       "      <td>0.281831</td>\n",
       "      <td>0.276622</td>\n",
       "      <td>0.261844</td>\n",
       "      <td>0.151006</td>\n",
       "      <td>0.311462</td>\n",
       "      <td>0.417386</td>\n",
       "      <td>0.224337</td>\n",
       "      <td>0.157114</td>\n",
       "      <td>0.402013</td>\n",
       "      <td>0.471765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16006441</th>\n",
       "      <td>0.332754</td>\n",
       "      <td>0.155462</td>\n",
       "      <td>0.155280</td>\n",
       "      <td>0.116425</td>\n",
       "      <td>0.225083</td>\n",
       "      <td>0.240832</td>\n",
       "      <td>0.215262</td>\n",
       "      <td>0.130713</td>\n",
       "      <td>0.256596</td>\n",
       "      <td>0.422437</td>\n",
       "      <td>0.181297</td>\n",
       "      <td>0.141775</td>\n",
       "      <td>0.392263</td>\n",
       "      <td>0.503044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16006442 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Band_1    Band_2    Band_3    Band_4    Band_5    Band_6  \\\n",
       "0         0.125326  0.129146  0.142650  0.108948  0.215784  0.229196   \n",
       "1         0.125326  0.137107  0.149482  0.111441  0.215784  0.229196   \n",
       "2         0.130973  0.145732  0.148654  0.112984  0.206724  0.204690   \n",
       "3         0.130973  0.141973  0.159006  0.112984  0.206724  0.204690   \n",
       "4         0.133362  0.149491  0.154037  0.113696  0.198855  0.198519   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "16006437  0.259774  0.096639  0.119255  0.076905  0.204101  0.326164   \n",
       "16006438  0.307776  0.114993  0.142443  0.082127  0.208870  0.346439   \n",
       "16006439  0.279105  0.099513  0.133540  0.085925  0.217215  0.312412   \n",
       "16006440  0.301694  0.131358  0.166874  0.132685  0.281831  0.276622   \n",
       "16006441  0.332754  0.155462  0.155280  0.116425  0.225083  0.240832   \n",
       "\n",
       "            Band_7    Band_8   Band_8A    Band_9   Band_11   Band_12  \\\n",
       "0         0.186645  0.107862  0.222532  0.300147  0.155787  0.139978   \n",
       "1         0.186645  0.100358  0.222532  0.300147  0.155787  0.139978   \n",
       "2         0.171383  0.088591  0.201452  0.300147  0.139554  0.133560   \n",
       "3         0.171383  0.088080  0.201452  0.300147  0.139554  0.133560   \n",
       "4         0.159936  0.085351  0.189167  0.300147  0.132187  0.129388   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "16006437  0.307154  0.195515  0.372609  0.533993  0.152923  0.084654   \n",
       "16006438  0.331161  0.229451  0.359765  0.457798  0.137644  0.075733   \n",
       "16006439  0.289189  0.159192  0.340360  0.479478  0.145761  0.080739   \n",
       "16006440  0.261844  0.151006  0.311462  0.417386  0.224337  0.157114   \n",
       "16006441  0.215262  0.130713  0.256596  0.422437  0.181297  0.141775   \n",
       "\n",
       "              NDVI      NDWI  Burn_Label  \n",
       "0         0.351473  0.544140           1  \n",
       "1         0.324234  0.577361           1  \n",
       "2         0.285683  0.612311           1  \n",
       "3         0.284123  0.630952           1  \n",
       "4         0.273951  0.631657           1  \n",
       "...            ...       ...         ...  \n",
       "16006437  0.625597  0.305978           0  \n",
       "16006438  0.667084  0.283575           0  \n",
       "16006439  0.533367  0.401099           0  \n",
       "16006440  0.402013  0.471765           0  \n",
       "16006441  0.392263  0.503044           0  \n",
       "\n",
       "[16006442 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reassign the dataframe with a list of the columns\n",
    "cols_norm = downsampled_df.columns.tolist()\n",
    "\n",
    "# Import Normalize technique\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize data\n",
    "scaler.fit(downsampled_df)\n",
    "\n",
    "# Save the scaler\n",
    "scaler_save_path = r'Export Model'\n",
    "save_path = os.path.join(scaler_save_path, 'MinMax_Scaler_DL.pkl')\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Normalize Data\n",
    "df_norm = scaler.transform(downsampled_df)\n",
    "df_norm = pd.DataFrame(df_norm, columns=cols_norm)\n",
    "\n",
    "# Check df_norm shape after normalization\n",
    "print(\"Shape of df_norm after normalization:\", df_norm.shape)\n",
    "\n",
    "# Concatenate df_norm with burn_label\n",
    "df_norm = pd.concat([df_norm.reset_index(drop=True), burn_label.reset_index(drop=True)], axis=1, sort=False)\n",
    "display(df_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Hyperparameters Analysis & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:GPU is available and will be used for training.\n",
      "INFO:__main__:GPU: /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Check if GPU is available\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    logger.info(\"GPU is available and will be used for training.\")\n",
    "    gpu_name = gpus[0].name\n",
    "    logger.info(f\"GPU: {gpu_name}\")\n",
    "else:\n",
    "    logger.info(\"GPU is not available, training will be done on CPU.\")\n",
    "\n",
    "# Ensure df_norm is already defined and preprocessed\n",
    "# Define the features and target\n",
    "X = df_norm.drop(columns=['Burn_Label'])  # Features\n",
    "y = df_norm['Burn_Label']  # Target\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_onehot = tf.keras.utils.to_categorical(y, num_classes=y.nunique())\n",
    "\n",
    "# Function to build the model\n",
    "def build_model(hidden_layers=1):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(X.shape[1],)))\n",
    "    for _ in range(hidden_layers):\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(y_onehot.shape[1], activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Hyperparameter Grid\n",
    "hidden_layers_options = [1, 2, 3]\n",
    "epochs_options = [10, 50, 100]\n",
    "batch_size_options = [16, 32]\n",
    "\n",
    "# Grid Search for Best Hyperparameters\n",
    "best_params = None\n",
    "best_score = 0\n",
    "\n",
    "for layers in hidden_layers_options:\n",
    "    for epochs in epochs_options:\n",
    "        for batch_size in batch_size_options:\n",
    "            # Perform k-fold cross-validation\n",
    "            kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "            scores = []\n",
    "            for train_idx, val_idx in kfold.split(X):\n",
    "                model = build_model(hidden_layers=layers)\n",
    "                model.fit(X.iloc[train_idx], y_onehot[train_idx], epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "                score = model.evaluate(X.iloc[val_idx], y_onehot[val_idx], verbose=0)[1]\n",
    "                scores.append(score)\n",
    "            avg_score = np.mean(scores)\n",
    "            print(f\"Layers: {layers}, Epochs: {epochs}, Batch Size: {batch_size}, Accuracy: {avg_score:.4f}\")\n",
    "            if avg_score > best_score:\n",
    "                best_score = avg_score\n",
    "                best_params = {'hidden_layers': layers, 'epochs': epochs, 'batch_size': batch_size}\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "# Train the Model with Best Hyperparameters on Entire Dataset\n",
    "best_model = build_model(hidden_layers=best_params['hidden_layers'])\n",
    "history = best_model.fit(X, y_onehot, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=1)\n",
    "\n",
    "# Plot Accuracy and Loss Graphs\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Cross-Validation Predictions\n",
    "y_pred = cross_val_predict(\n",
    "    estimator=tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=lambda: build_model(hidden_layers=best_params['hidden_layers']),\n",
    "                                                             epochs=best_params['epochs'],\n",
    "                                                             batch_size=best_params['batch_size'], verbose=0),\n",
    "    X=X, y=y, cv=10\n",
    ")\n",
    "\n",
    "# Classification Report as Pandas DataFrame\n",
    "report = classification_report(y, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "print(report_df)\n",
    "\n",
    "# Confusion Matrix Heatmap\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FCNN_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
