{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNN) for Burn Area Classification with Sentinel-2 Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import earthpy.plot as ep\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import from_levels_and_colors\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from IPython.display import display, Markdown\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "FEATURES = ['B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B11', 'B12', 'dNBR', 'NDVI', 'NDWI', 'Burn_Label']\n",
    "FOLDER_PATH = 'Raster_Train'\n",
    "\n",
    "# Find all .tif files in the folder\n",
    "tif_files = glob.glob(os.path.join(FOLDER_PATH, '*.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and concatenate all data\n",
    "all_data = []\n",
    "\n",
    "for file in tif_files:\n",
    "    with rasterio.open(file) as src:\n",
    "        bands = src.read()  # (bands, height, width)\n",
    "        bands_reshaped = bands.reshape(bands.shape[0], -1).T  # (pixels, bands)\n",
    "        df = pd.DataFrame(bands_reshaped, columns=FEATURES)\n",
    "        all_data.append(df)\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "df_all = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Drop NaNs or invalid values (optional, but often needed)\n",
    "df_all = df_all.dropna()\n",
    "\n",
    "# Downsample the data by Burn_Label\n",
    "df_majority = df_all[df_all['Burn_Label'] == 0]\n",
    "df_minority = df_all[df_all['Burn_Label'] == 1]\n",
    "\n",
    "df_majority_downsampled = resample(\n",
    "    df_majority,\n",
    "    replace=False,      # sample without replacement\n",
    "    n_samples=len(df_minority),  # match minority class\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combine balanced data\n",
    "df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# Shuffle the result\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Show preview\n",
    "print(df_balanced.head())\n",
    "print(df_balanced['Burn_Label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and label\n",
    "X = df_balanced[FEATURES[:-1]].values  # all bands except the last one\n",
    "y = df_balanced[FEATURES[-1]].values   # last band is the label\n",
    "\n",
    "# Remove pixels with no data if necessary (e.g., NaNs or a mask value)\n",
    "valid_idx = ~np.isnan(X).any(axis=1)\n",
    "X = X[valid_idx]\n",
    "y = y[valid_idx]\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape for CNN: (samples, height, width, channels)\n",
    "# We'll reshape each pixel as a 1x1 image with multiple bands\n",
    "X_cnn = X_scaled.reshape(-1, 1, 1, X.shape[1])\n",
    "\n",
    "# Binary classification assumed here (e.g., burned vs not burned)\n",
    "y_cnn = (y > 0).astype(np.uint8)  # or apply thresholding logic\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cnn, y_cnn, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train Dataset Shape:\", X_train.shape)\n",
    "print(\"Test Dataset Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(1, 1, X.shape[1])),\n",
    "    layers.Conv2D(16, (1, 1), activation='relu'),\n",
    "    layers.Conv2D(32, (1, 1), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=256,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Accuracy and Loss Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy and loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(np.uint8)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nGenerating classification report and confusion matrix...\")\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a summary of the results\n",
    "cnn_result = [{\n",
    "    'Classifier': 'Convolutional Neural Network',\n",
    "    'Model Definition': model,\n",
    "    'Class 0 - Precision': report['0']['precision'],\n",
    "    'Class 0 - Recall': report['0']['recall'],\n",
    "    'Class 0 - F1-Score': report['0']['f1-score'],\n",
    "    'Class 1 - Precision': report['1']['precision'],\n",
    "    'Class 1 - Recall': report['1']['recall'],\n",
    "    'Class 1 - F1-Score': report['1']['f1-score'],\n",
    "    'Average - Precision': report['macro avg']['precision'],\n",
    "    'Average - Recall': report['macro avg']['recall'],\n",
    "    'Average - F1-Score': report['macro avg']['f1-score'],\n",
    "    'Accuracy': report['accuracy'],\n",
    "    'Confusion Matrix': cm\n",
    "}]\n",
    "    \n",
    "cnn_result_df = pd.DataFrame(cnn_result)\n",
    "    \n",
    "display(Markdown(\"### Classification Report of Convolutional Neural Network\"))\n",
    "display(cnn_result_df)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix - Convolutional Neural Network (CNN)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RIDA_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
